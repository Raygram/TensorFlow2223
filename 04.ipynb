{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 3GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Benny\\AppData\\Local\\Temp\\ipykernel_2728\\2726633912.py\", line 61, in None  *\n        lambda x1, x2: (x1[0], x2[0], x1[1] - x2[2])\n\n    IndexError: tuple index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 72\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m zipped_ds\n\u001b[0;32m     71\u001b[0m train_ds_a \u001b[39m=\u001b[39m preprocess_a(ds_train, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m) \u001b[39m#train_ds.apply(preprocess)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m train_ds_b \u001b[39m=\u001b[39m preprocess_b(ds_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m) \u001b[39m#train_ds.apply(preprocess)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m val_ds_a \u001b[39m=\u001b[39m preprocess_a(ds_test, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m) \u001b[39m#val_ds.apply(preprocess)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m val_ds_b \u001b[39m=\u001b[39m preprocess_b(ds_test, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn [16], line 61\u001b[0m, in \u001b[0;36mpreprocess_b\u001b[1;34m(data, batch_size)\u001b[0m\n\u001b[0;32m     58\u001b[0m zipped_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mzip((data\u001b[39m.\u001b[39mshuffle(\u001b[39m2000\u001b[39m), \n\u001b[0;32m     59\u001b[0m                                  data\u001b[39m.\u001b[39mshuffle(\u001b[39m2000\u001b[39m)))\n\u001b[0;32m     60\u001b[0m \u001b[39m# map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *x1[1] + x2[1] >= 5\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m zipped_ds \u001b[39m=\u001b[39m zipped_ds\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x1, x2: (x1[\u001b[39m0\u001b[39;49m], x2[\u001b[39m0\u001b[39;49m], x1[\u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39;49m x2[\u001b[39m2\u001b[39;49m]))\n\u001b[0;32m     62\u001b[0m \u001b[39m# transform boolean target to int\u001b[39;00m\n\u001b[0;32m     63\u001b[0m zipped_ds \u001b[39m=\u001b[39m zipped_ds\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x1, x2, t: (x1,x2, tf\u001b[39m.\u001b[39mcast(t, tf\u001b[39m.\u001b[39mint32)))\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2200\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2201\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   5399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 5400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5401\u001b[0m     map_func,\n\u001b[0;32m   5402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5403\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5404\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5412\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32mc:\\Users\\Benny\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Benny\\AppData\\Local\\Temp\\ipykernel_2728\\2726633912.py\", line 61, in None  *\n        lambda x1, x2: (x1[0], x2[0], x1[1] - x2[2])\n\n    IndexError: tuple index out of range\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def normalize_img(image, label):\n",
    "  Normalizes images: `uint8` -> `float32`.\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\"\"\"\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def preprocess_a(data, batch_size):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
    "                                     data.shuffle(2000)))\n",
    "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *x1[1] + x2[1] >= 5\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] + x2[1] >= 5))\n",
    "    # transform boolean target to int\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    # batch the dataset\n",
    "    zipped_ds = zipped_ds.batch(batch_size)\n",
    "    # prefetch\n",
    "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return zipped_ds\n",
    "\n",
    "def preprocess_b(data, batch_size):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
    "                                     data.shuffle(2000)))\n",
    "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *x1[1] + x2[1] >= 5\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1] - x2[2]))\n",
    "    # transform boolean target to int\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    # batch the dataset\n",
    "    zipped_ds = zipped_ds.batch(batch_size)\n",
    "    # prefetch\n",
    "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return zipped_ds\n",
    "    \n",
    "\n",
    "train_ds_a = preprocess_a(ds_train, batch_size=128) #train_ds.apply(preprocess)\n",
    "train_ds_b = preprocess_b(ds_train, batch_size=128) #train_ds.apply(preprocess)\n",
    "val_ds_a = preprocess_a(ds_test, batch_size=128) #val_ds.apply(preprocess)\n",
    "\n",
    "val_ds_b = preprocess_b(ds_test, batch_size=128) #val_ds.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.2562 - sparse_categorical_accuracy: 0.9261 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9613\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9700\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.0838 - val_sparse_categorical_accuracy: 0.9739\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0826 - val_sparse_categorical_accuracy: 0.9732\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0801 - val_sparse_categorical_accuracy: 0.9750\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0849 - val_sparse_categorical_accuracy: 0.9746\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0732 - val_sparse_categorical_accuracy: 0.9781\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0741 - val_sparse_categorical_accuracy: 0.9795\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0828 - val_sparse_categorical_accuracy: 0.9772\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0810 - val_sparse_categorical_accuracy: 0.9782\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0776 - val_sparse_categorical_accuracy: 0.9793\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9769\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9774\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9783\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9789\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9782\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.1094 - val_sparse_categorical_accuracy: 0.9772\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9779\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9981 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b91f5c92a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    validation_data=ds_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/6\n",
    "469/469 [==============================] - 6s 7ms/step - loss: 0.3664 - sparse_categorical_accuracy: 0.8992 - val_loss: 0.2011 - val_sparse_categorical_accuracy: 0.9396\n",
    "Epoch 2/6\n",
    "469/469 [==============================] - 3s 6ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1393 - val_sparse_categorical_accuracy: 0.9604\n",
    "Epoch 3/6\n",
    "469/469 [==============================] - 3s 6ms/step - loss: 0.1186 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9656\n",
    "Epoch 4/6\n",
    "469/469 [==============================] - 3s 6ms/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9708\n",
    "Epoch 5/6\n",
    "469/469 [==============================] - 3s 6ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9731\n",
    "Epoch 6/6\n",
    "469/469 [==============================] - 3s 6ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0825 - val_sparse_categorical_accuracy: 0.9741"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('iannwtf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63f83f16703f6be7ffd0b8723f3797201bb87b90d9af5c25669f8b533ad7062b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
