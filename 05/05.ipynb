{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikod\\miniconda3\\envs\\iannwtf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# in a notebook, load the tensorboard extension, not needed for scripts\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 3GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, batch_size):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, tf.float32), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/255, t)))\n",
    "    # batch the dataset\n",
    "    data = data.batch(batch_size)\n",
    "    # prefetch\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "train_ds = preprocess(train_ds, 64)\n",
    "test_ds = preprocess(test_ds,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 30, 64)        640       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 32, 28, 64)        12352     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 32, 26, 64)        12352     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 64)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,994\n",
      "Trainable params: 25,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model using the functional API\n",
    "# input layer\n",
    "i = tf.keras.Input(shape=[32,32,3])\n",
    "# i = tf.keras.Input(shape=(3074))\n",
    "# your code here, just add convolutional layers\n",
    "\n",
    "conv_1 = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(i)\n",
    "conv_2 = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(conv_1)\n",
    "conv_3 = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(conv_2)\n",
    "\n",
    "\n",
    "# pooling layer to get 1D data\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(conv_3)\n",
    "\n",
    "# last hidden layer i.e.. output layer\n",
    "y = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    " \n",
    "model = tf.keras.Model(i, y)\n",
    " \n",
    "# model description\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "782/782 [==============================] - 156s 196ms/step - loss: 2.0348 - accuracy: 0.2317 - val_loss: 1.9351 - val_accuracy: 0.2763\n",
      "Epoch 2/8\n",
      "782/782 [==============================] - 165s 211ms/step - loss: 1.9074 - accuracy: 0.2886 - val_loss: 1.8477 - val_accuracy: 0.3213\n",
      "Epoch 3/8\n",
      "782/782 [==============================] - 159s 204ms/step - loss: 1.8421 - accuracy: 0.3235 - val_loss: 1.7980 - val_accuracy: 0.3418\n",
      "Epoch 4/8\n",
      "782/782 [==============================] - 159s 204ms/step - loss: 1.7946 - accuracy: 0.3476 - val_loss: 1.7572 - val_accuracy: 0.3639\n",
      "Epoch 5/8\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 1.7589 - accuracy: 0.3660 - val_loss: 1.7242 - val_accuracy: 0.3818\n",
      "Epoch 6/8\n",
      "782/782 [==============================] - 149s 191ms/step - loss: 1.7311 - accuracy: 0.3800 - val_loss: 1.6993 - val_accuracy: 0.3934\n",
      "Epoch 7/8\n",
      "782/782 [==============================] - 149s 190ms/step - loss: 1.7086 - accuracy: 0.3908 - val_loss: 1.6814 - val_accuracy: 0.4015\n",
      "Epoch 8/8\n",
      "782/782 [==============================] - 148s 190ms/step - loss: 1.6889 - accuracy: 0.4014 - val_loss: 1.6679 - val_accuracy: 0.4077\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "# You could also experiment around with different hyper parameter, but this configuration should work fine\n",
    "num_epochs = 8\n",
    "history = model.fit(train_ds, validation_data = test_ds,  epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('iannwtf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dc7ff763bccf8d187fcb6b4b66c3bdc5a17148cd281fe390abc7e32c62a720d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
